import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os


# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
class AnimalDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['00_Goat', '01_Wild boar', '02_Squirrel', '03_Raccoon',
                        '04_Asiatic black bear', '05_Hare', '06_Weasel',
                        '07_Haron', '08_Dog', '09_Cat']
        self.images = []
        self.labels = []

        print(f"ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘: {root_dir}")
        for idx, class_name in enumerate(self.classes):
            class_dir = os.path.join(root_dir, class_name)

            if not os.path.exists(class_dir):
                print(f"âš ï¸ ê²½ê³ : {class_dir} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!")
                continue

            files = [f for f in os.listdir(class_dir)
                     if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
            print(f"  {class_name}: {len(files)}ì¥")

            for img_name in files:
                self.images.append(os.path.join(class_dir, img_name))
                self.labels.append(idx)

        print(f"âœ… ì´ {len(self.images)}ì¥ ë¡œë“œ ì™„ë£Œ\n")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        try:
            image = Image.open(self.images[idx]).convert('RGB')
            label = self.labels[idx]

            if self.transform:
                image = self.transform(image)

            return image, label
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {self.images[idx]}")
            print(f"   ì˜¤ë¥˜: {e}")
            # ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë°˜í™˜ (ì—ëŸ¬ ë°©ì§€)
            return torch.zeros(3, 240, 240), self.labels[idx]


# ë°ì´í„° ì „ì²˜ë¦¬
train_transform = transforms.Compose([
    transforms.Resize((240, 240)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((240, 240)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

print("=" * 60)
print("ë™ë¬¼ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
print("=" * 60)
print()

# ë°ì´í„° ë¡œë” ìƒì„±
train_dataset = AnimalDataset('datasets/training', transform=train_transform)
val_dataset = AnimalDataset('datasets/validation', transform=val_transform)

# ë°°ì¹˜ í¬ê¸°: GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • (GTX 1650ì€ 16 ê¶Œì¥)
batch_size = 16
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}")
print(f"í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
print(f"ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
print()

# EfficientNet-B1 ëª¨ë¸ ë¡œë“œ ë° ìˆ˜ì •
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
model = models.efficientnet_b1(weights='IMAGENET1K_V1')  # ìµœì‹  ë°©ì‹
num_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_features, 10)  # 10ê°œ í´ë˜ìŠ¤

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
if device.type == 'cuda':
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")
print()

model = model.to(device)

# í•™ìŠµ ì„¤ì •
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# í•™ìŠµ ë£¨í”„
num_epochs = 30
best_acc = 0.0

print("=" * 60)
print("í•™ìŠµ ì‹œì‘!")
print("=" * 60)
print()

for epoch in range(num_epochs):
    # í•™ìŠµ ëª¨ë“œ
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (10 ë°°ì¹˜ë§ˆë‹¤)
        if (batch_idx + 1) % 10 == 0:
            print(f"  Batch [{batch_idx + 1}/{len(train_loader)}] "
                  f"Loss: {loss.item():.4f} "
                  f"Acc: {100. * correct / total:.2f}%")

    train_acc = 100. * correct / total

    # ê²€ì¦ ëª¨ë“œ
    model.eval()
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = outputs.max(1)
            val_total += labels.size(0)
            val_correct += predicted.eq(labels).sum().item()

    val_acc = 100. * val_correct / val_total

    print()
    print(f'Epoch [{epoch + 1}/{num_epochs}]')
    print(f'Train Loss: {running_loss / len(train_loader):.4f}, Train Acc: {train_acc:.2f}%')
    print(f'Val Acc: {val_acc:.2f}%')
    print(f'Best Val Acc: {best_acc:.2f}%')
    print("-" * 60)

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if val_acc > best_acc:
        best_acc = val_acc
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'accuracy': val_acc,
            'class_names': train_dataset.classes
        }, 'efficientnet_classifier_model.pth')
        print(f"âœ… ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! ëª¨ë¸ ì €ì¥ë¨ (Val Acc: {val_acc:.2f}%)")
        print("-" * 60)

    scheduler.step()

print()
print("=" * 60)
print(f'í•™ìŠµ ì™„ë£Œ! Best Validation Accuracy: {best_acc:.2f}%')
print("=" * 60)
print()

# ìµœì¢… ëª¨ë¸ ì €ì¥ (ë°°í¬ìš©)
print("ë°°í¬ìš© ëª¨ë¸ ì €ì¥ ì¤‘...")
torch.save({
    'model_state_dict': model.state_dict(),
    'class_names': ['00_Goat', '01_Wild boar', '02_Squirrel', '03_Raccoon',
                    '04_Asiatic black bear', '05_Hare', '06_Weasel',
                    '07_Haron', '08_Dog', '09_Cat'],
    'input_size': (240, 240),
    'model_architecture': 'efficientnet_b1',
    'num_classes': 10,
    'accuracy': best_acc
}, 'animal_classifier_model.pth')

print('âœ… ìµœì¢… ëª¨ë¸ì´ animal_classifier_model.pthë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!')
print()
print("ìƒì„±ëœ íŒŒì¼:")
print("  - efficientnet_classifier_model.pth (í•™ìŠµ ì¤‘ ìµœê³  ì„±ëŠ¥ ëª¨ë¸)")
print("  - animal_classifier_model.pth (ë°°í¬ìš© ìµœì¢… ëª¨ë¸)")